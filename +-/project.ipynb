{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "# Загрузка модели YOLOv8\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Путь к видео\n",
    "video_path = \"457701_Asia_Korea_640x480.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error opening file {video_path}\")\n",
    "    exit()\n",
    "\n",
    "print(\"start\")\n",
    "\n",
    "# Получение FPS и размеров видео\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print(width,height)\n",
    "\n",
    "# Создание VideoWriter для записи выходного видео\n",
    "output_path = \"output.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Кодек для записи\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width,height))\n",
    "# словарь для хранения истории трэков\n",
    "track_history = defaultdict(lambda: [])\n",
    "x_box = []\n",
    "y_box = []\n",
    "\n",
    "def predict_position(track, future_time, fps):\n",
    "    if len(track) < 2:\n",
    "        return track[-1]\n",
    "\n",
    "    N = min(len(track), 25)\n",
    "    track = np.array(track[-N:])\n",
    "\n",
    "    times = np.arange(-N + 1, 1)\n",
    "\n",
    "    A = np.vstack([times, np.ones(len(times))]).T\n",
    "    k_x, b_x = np.linalg.lstsq(A, track[:, 0], rcond=None)[0]\n",
    "    k_y, b_y = np.linalg.lstsq(A, track[:, 1], rcond=None)[0]\n",
    "\n",
    "    future_frames = future_time * fps\n",
    "    future_x = k_x * future_frames + b_x\n",
    "    future_y = k_y * future_frames + b_y\n",
    "\n",
    "    return future_x, future_y\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if not success:\n",
    "        print(\"reading error\")\n",
    "        break\n",
    "\n",
    "    results = model.track(frame, persist=True)\n",
    "\n",
    "    if results[0].boxes is not None and results[0].boxes.id is not None:\n",
    "         # Получение координат боксов и идентификаторов треков\n",
    "        boxes = results[0].boxes.xywh.cpu() # получение координат боксов\n",
    "        track_ids = results[0].boxes.id.int().cpu().tolist() # получение айдишников\n",
    "\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        for box, track_id in zip(boxes, track_ids):\n",
    "            x, y, w, h = box #координаты центра и размеры бокса\n",
    "            x_box.append(int(box[0]))\n",
    "            y_box.append(int(box[1]))\n",
    "            track = track_history[track_id] \n",
    "            track.append((float(x), float(y))) #добавление координат в историю\n",
    "            if len(track) > 30: #длина истории 30 кадров максимум\n",
    "                track.pop(0)\n",
    "            #рисование линий трэка\n",
    "            points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
    "            cv2.polylines(annotated_frame, [points], isClosed=False, color=(230, 230, 230), thickness=3)\n",
    "\n",
    "            future_time = 1.5  # секунд\n",
    "            future_x, future_y = predict_position(track, future_time, fps)\n",
    "\n",
    "            if len(track) > 1:\n",
    "                last_x, last_y = track[-1]\n",
    "                cv2.line(annotated_frame, (int(last_x), int(last_y)), (int(future_x), int(future_y)), (0, 255, 255), 2)\n",
    "\n",
    "            cv2.circle(annotated_frame, (int(future_x), int(future_y)), 5, (0, 255, 0), -1)\n",
    "            cv2.putText(annotated_frame, 'Predicted', (int(future_x), int(future_y)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Запись кадра в выходное видео\n",
    "\n",
    "        out.write(annotated_frame)\n",
    "\n",
    "        cv2.imshow(\"YOLOv11 Tracking\", annotated_frame)\n",
    "    else:\n",
    "        cv2.imshow(\"YOLOv11 Tracking\", frame)\n",
    "\n",
    "        # Запись кадра в выходное видео\n",
    "        out.write(frame)\n",
    "\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#создание графика\n",
    "fig, ax = plt.subplots()\n",
    "t = x_box\n",
    "z = y_box\n",
    "scat = ax.scatter(t[0], z[0])\n",
    "ax.set(xlim=[0,width], ylim=[0, height], xlabel='X', ylabel='Y')\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "def update(frame):\n",
    "    # for each frame, update the data stored on each artist.\n",
    "    x = t[:frame]\n",
    "    y = z[:frame]\n",
    "    # update the scatter plot:\n",
    "    data = np.stack([x, y]).T\n",
    "    scat.set_offsets(data)\n",
    "    return (scat)\n",
    "\n",
    "\n",
    "ani = animation.FuncAnimation(fig=fig, func=update, frames=40, interval=30)\n",
    "ani.save(filename=\"pillow_example.gif\", writer=\"pillow\")\n",
    "#ПОСМОТРЕТЬ ПОЧЕМУ ВИДЕО НЕ ПОЛУЧАЕТСЯ И ГРАФИК"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
